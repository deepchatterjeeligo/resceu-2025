{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ea2f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams.update(\n",
    "    {\n",
    "        \"text.usetex\": True,\n",
    "        \"font.family\": \"Computer Modern\",\n",
    "        \"font.size\": 16,\n",
    "        \"figure.dpi\": 100,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Most of this notebook can be run on CPU in a reasonable amount of time.\n",
    "# The example training at the end cannot be.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a987800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desired duration of time-domain waveform\n",
    "waveform_duration = 8\n",
    "# Sample rate of all the data we'll be using today\n",
    "sample_rate = 2048\n",
    "\n",
    "# Define minimum, maximum, and reference frequencies\n",
    "f_min = 20\n",
    "f_max = 1024\n",
    "f_ref = 20\n",
    "\n",
    "nyquist = sample_rate / 2\n",
    "num_samples = int(waveform_duration * sample_rate)\n",
    "num_freqs = num_samples // 2 + 1\n",
    "\n",
    "# Create an array of frequency values at which to generate our waveform\n",
    "# At the moment, only frequency-domain approximants have been implemented\n",
    "frequencies = torch.linspace(0, nyquist, num_freqs).to(device)\n",
    "freq_mask = (frequencies >= f_min) * (frequencies < f_max).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1a911b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml4gw.distributions import PowerLaw, Sine, Cosine, DeltaFunction\n",
    "from torch.distributions import Uniform\n",
    "\n",
    "# On CPU, keep the number of waveforms around 100. On GPU, you can go higher,\n",
    "# subject to memory constraints.\n",
    "num_waveforms = 500\n",
    "\n",
    "# Create a dictionary of parameter distributions\n",
    "# This is not intended to be an astrophysically\n",
    "# meaningful distribution\n",
    "param_dict = {\n",
    "    \"chirp_mass\": PowerLaw(25, 40, -2.35),\n",
    "    \"mass_ratio\": Uniform(0.125, 0.999),\n",
    "    \"chi1\": Uniform(-0.999, 0.999),\n",
    "    \"chi2\": Uniform(-0.999, 0.999),\n",
    "    \"distance\": PowerLaw(100, 1000, 2),\n",
    "    \"phic\": DeltaFunction(0),\n",
    "    \"inclination\": Sine(),\n",
    "}\n",
    "\n",
    "# And then sample from each of those distributions\n",
    "params = {\n",
    "    k: v.sample((num_waveforms,)).to(device) for k, v in param_dict.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55d80a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml4gw.waveforms import IMRPhenomD\n",
    "\n",
    "approximant = IMRPhenomD().to(device)\n",
    "\n",
    "# Calling the approximant with the frequency array, reference frequency, and waveform parameters\n",
    "# returns the cross and plus polarizations\n",
    "hc_f, hp_f = approximant(f=frequencies[freq_mask], f_ref=f_ref, **params)\n",
    "print(hc_f.shape, hp_f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf01d7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(frequencies[freq_mask].cpu(), torch.abs(hp_f[0]).cpu())\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Frequency (Hz)\")\n",
    "plt.ylabel(\"$\\\\vert h \\\\vert$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292d6a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml4gw.waveforms.generator import TimeDomainCBCWaveformGenerator\n",
    "from ml4gw.waveforms.conversion import chirp_mass_and_mass_ratio_to_components\n",
    "\n",
    "waveform_generator = TimeDomainCBCWaveformGenerator(\n",
    "    approximant=approximant,\n",
    "    sample_rate=sample_rate,\n",
    "    f_min=f_min,\n",
    "    duration=waveform_duration,\n",
    "    right_pad=0.5,\n",
    "    f_ref=f_ref,\n",
    ").to(device)\n",
    "\n",
    "params[\"mass_1\"], params[\"mass_2\"] = chirp_mass_and_mass_ratio_to_components(\n",
    "    params[\"chirp_mass\"], params[\"mass_ratio\"]\n",
    ")\n",
    "\n",
    "params[\"s1z\"], params[\"s2z\"] = params[\"chi1\"], params[\"chi2\"]\n",
    "\n",
    "hc, hp = waveform_generator(**params)\n",
    "print(hc.shape, hp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7f8822",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = torch.arange(0, waveform_duration, 1 / sample_rate)\n",
    "plt.plot(times, hp[0].cpu())\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Strain\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c63fd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml4gw.gw import get_ifo_geometry, compute_observed_strain\n",
    "\n",
    "# Define probability distributions for sky location and polarization angle\n",
    "dec = Cosine()\n",
    "psi = Uniform(0, torch.pi)\n",
    "phi = Uniform(-torch.pi, torch.pi)\n",
    "\n",
    "# The interferometer geometry for V1 and K1 are also in ml4gw\n",
    "ifos = [\"H1\", \"L1\"]\n",
    "tensors, vertices = get_ifo_geometry(*ifos)\n",
    "\n",
    "# Pass the detector geometry, along with the polarizations and sky parameters,\n",
    "# to get the observed strain\n",
    "waveforms = compute_observed_strain(\n",
    "    dec=dec.sample((num_waveforms,)).to(device),\n",
    "    psi=psi.sample((num_waveforms,)).to(device),\n",
    "    phi=phi.sample((num_waveforms,)).to(device),\n",
    "    detector_tensors=tensors.to(device),\n",
    "    detector_vertices=vertices.to(device),\n",
    "    sample_rate=sample_rate,\n",
    "    cross=hc,\n",
    "    plus=hp,\n",
    ")\n",
    "print(waveforms.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a4bb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(times, waveforms[0, 0].cpu(), label=\"H1\", alpha=0.5)\n",
    "plt.plot(times, waveforms[0, 1].cpu(), label=\"L1\", alpha=0.5)\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Strain\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38937eb1",
   "metadata": {},
   "source": [
    "## Get some background and generate injections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b581843",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gwpy.timeseries import TimeSeries, TimeSeriesDict\n",
    "from pathlib import Path\n",
    "\n",
    "# Point this to whatever directory you want to house\n",
    "# all of the data products this notebook creates\n",
    "data_dir = Path(\"./data\")\n",
    "\n",
    "# And this to the directory where you want to download the data\n",
    "background_dir = data_dir / \"background_data\"\n",
    "background_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec48d0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# These are the GPS time of the start and end of the segments.\n",
    "# There's no particular reason for these times, other than that they\n",
    "# contain analysis-ready data\n",
    "segments = [\n",
    "    (1240579783, 1240587612), \n",
    "    (1240594562, 1240606748), \n",
    "    (1240624412, 1240644412),\n",
    "    (1240644412, 1240654372),\n",
    "    (1240658942, 1240668052),\n",
    "]\n",
    "\n",
    "for (start, end) in segments:\n",
    "    # Download the data from GWOSC. This will take a few minutes.\n",
    "    duration = end - start\n",
    "    fname = background_dir / f\"background-{start}-{duration}.hdf5\"\n",
    "    if fname.exists():\n",
    "        continue\n",
    "\n",
    "    ts_dict = TimeSeriesDict()\n",
    "    for ifo in ifos:\n",
    "        ts_dict[ifo] = TimeSeries.fetch_open_data(ifo, start, end, cache=True)\n",
    "    ts_dict = ts_dict.resample(sample_rate)\n",
    "    ts_dict.write(fname, format=\"hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a190c2",
   "metadata": {},
   "source": [
    "### Dataloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff3b712",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls data/background_data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af319a2",
   "metadata": {},
   "source": [
    "# Power Spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73b67f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml4gw.transforms import SpectralDensity\n",
    "import h5py\n",
    "\n",
    "fftlength = 2\n",
    "spectral_density = SpectralDensity(\n",
    "    sample_rate=sample_rate,\n",
    "    fftlength=fftlength,\n",
    "    overlap=None,\n",
    "    average=\"median\",\n",
    ").to(device)\n",
    "\n",
    "# This is H1 and L1 data from O3 that I downloaded earlier\n",
    "# We have tools for dataloading that I'll get to later\n",
    "background_file = background_dir / \"background-1240576000-4096.hdf5\"\n",
    "with h5py.File(background_file, \"r\") as f:\n",
    "    background = [torch.Tensor(f[ifo][:]) for ifo in ifos]\n",
    "    background = torch.stack(background).to(device)\n",
    "\n",
    "# Note cast to double\n",
    "psd = spectral_density(background.double())\n",
    "print(psd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e25c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = torch.linspace(0, nyquist, psd.shape[-1])\n",
    "plt.plot(freqs, psd.cpu()[0], label=\"H1\")\n",
    "plt.plot(freqs, psd.cpu()[1], label=\"L1\")\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Frequency (Hz)\")\n",
    "plt.ylabel(\"PSD (1/Hz)\")\n",
    "plt.legend()\n",
    "plt.xlim((10, 1000))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3aa892",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml4gw.gw import compute_ifo_snr, compute_network_snr\n",
    "\n",
    "# Note need to interpolate\n",
    "if psd.shape[-1] != num_freqs:\n",
    "    # Adding dummy dimensions for consistency\n",
    "    while psd.ndim < 3:\n",
    "        psd = psd[None]\n",
    "    psd = torch.nn.functional.interpolate(\n",
    "        psd, size=(num_freqs,), mode=\"linear\"\n",
    "    )\n",
    "\n",
    "# We can compute both the individual and network SNRs\n",
    "# The SNR calculation starts at the minimum frequency we\n",
    "# specified earlier and goes to the maximum\n",
    "# TODO: There's probably no reason to have multiple functions\n",
    "h1_snr = compute_ifo_snr(\n",
    "    responses=waveforms[:, 0],\n",
    "    psd=psd[:, 0],\n",
    "    sample_rate=sample_rate,\n",
    "    highpass=f_min,\n",
    ")\n",
    "l1_snr = compute_ifo_snr(\n",
    "    responses=waveforms[:, 1],\n",
    "    psd=psd[:, 1],\n",
    "    sample_rate=sample_rate,\n",
    "    highpass=f_min,\n",
    ")\n",
    "network_snr = compute_network_snr(\n",
    "    responses=waveforms, psd=psd, sample_rate=sample_rate, highpass=f_min\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c66572",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(h1_snr.cpu(), bins=25, alpha=0.5, label=\"H1\")\n",
    "plt.hist(l1_snr.cpu(), bins=25, alpha=0.5, label=\"L1\")\n",
    "plt.hist(network_snr.cpu(), bins=25, alpha=0.5, label=\"Network\")\n",
    "plt.xlabel(\"Optimal SNR\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlim(0, 100)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8963eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml4gw.gw import reweight_snrs\n",
    "\n",
    "target_snrs = PowerLaw(12, 100, -3).sample((num_waveforms,)).to(device)\n",
    "# Each waveform will be scaled by the ratio of its target SNR to its current SNR\n",
    "waveforms = reweight_snrs(\n",
    "    responses=waveforms,\n",
    "    target_snrs=target_snrs,\n",
    "    psd=psd,\n",
    "    sample_rate=sample_rate,\n",
    "    highpass=f_min,\n",
    ")\n",
    "\n",
    "network_snr = compute_network_snr(\n",
    "    responses=waveforms, psd=psd, sample_rate=sample_rate, highpass=f_min\n",
    ")\n",
    "\n",
    "plt.hist(network_snr.cpu(), bins=25, alpha=0.5, label=\"Network\")\n",
    "plt.xlabel(\"SNR\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlim(0, 100)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686b9ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml4gw.dataloading import Hdf5TimeSeriesDataset\n",
    "\n",
    "# Defining some parameters for future use, and to\n",
    "# determine the size of the windows to sample.\n",
    "# We're going to be whitening the last part of each\n",
    "# window with a PSD calculated from the first part,\n",
    "# so we need to grab enough data to do that\n",
    "\n",
    "# Length of data used to estimate PSD\n",
    "psd_length = 16\n",
    "psd_size = int(psd_length * sample_rate)\n",
    "\n",
    "# Length of filter. A segment of length fduration / 2\n",
    "# will be cropped from either side after whitening\n",
    "fduration = 2\n",
    "\n",
    "# Length of window of data we'll feed to our network\n",
    "kernel_length = 1.5\n",
    "kernel_size = int(1.5 * sample_rate)\n",
    "\n",
    "# Total length of data to sample\n",
    "window_length = psd_length + fduration + kernel_length\n",
    "\n",
    "fnames = list(background_dir.iterdir())\n",
    "dataloader = Hdf5TimeSeriesDataset(\n",
    "    fnames=fnames,\n",
    "    channels=ifos,\n",
    "    kernel_size=int(window_length * sample_rate),\n",
    "    batch_size=2\n",
    "    * num_waveforms,  # Grab twice as many background samples as we have waveforms\n",
    "    batches_per_epoch=1,  # Just doing 1 here for demonstration purposes\n",
    "    coincident=False,\n",
    ")\n",
    "\n",
    "background_samples = [x for x in dataloader][0].to(device)\n",
    "print(background_samples.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84567105",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml4gw.transforms import Whiten\n",
    "\n",
    "whiten = Whiten(\n",
    "    fduration=fduration, sample_rate=sample_rate, highpass=f_min\n",
    ").to(device)\n",
    "\n",
    "# Create PSDs using the first psd_length seconds of each sample\n",
    "# with the SpectralDensity module we defined earlier\n",
    "psd = spectral_density(background_samples[..., :psd_size].double())\n",
    "print(f\"PSD shape: {psd.shape}\")\n",
    "\n",
    "# Take everything after the first psd_length as our input kernel\n",
    "kernel = background_samples[..., psd_size:]\n",
    "# And whiten using our PSDs\n",
    "whitened_kernel = whiten(kernel, psd)\n",
    "print(f\"Kernel shape: {kernel.shape}\")\n",
    "print(f\"Whitened kernel shape: {whitened_kernel.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d46b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = torch.arange(0, kernel_length + fduration, 1 / sample_rate)\n",
    "plt.plot(times, kernel[0, 0].cpu())\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Strain\")\n",
    "plt.show()\n",
    "\n",
    "times = torch.arange(0, kernel_length, 1 / sample_rate)\n",
    "plt.plot(times, whitened_kernel[0, 0].cpu())\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Whitened strain\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691e9bee",
   "metadata": {},
   "source": [
    "# Inject waveforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ec841c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad = int(fduration / 2 * sample_rate)\n",
    "injected = kernel.detach().clone()\n",
    "# Inject waveforms into every other background sample\n",
    "injected[::2, :, pad:-pad] += waveforms[..., -kernel_size:]\n",
    "# And whiten with the same PSDs as before\n",
    "whitened_injected = whiten(injected, psd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3ff8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factor of 2 because we injected every other sample\n",
    "idx = 2 * torch.argmax(network_snr)\n",
    "\n",
    "times = torch.arange(0, kernel_length + fduration, 1 / sample_rate)\n",
    "plt.plot(times, injected[idx, 0].cpu())\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Strain\")\n",
    "plt.show()\n",
    "\n",
    "times = torch.arange(0, kernel_length, 1 / sample_rate)\n",
    "plt.plot(times, whitened_injected[idx, 0].cpu())\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Whitened strain\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c87a469",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.zeros(len(injected))\n",
    "y[::2] = 1\n",
    "with h5py.File(data_dir / \"validation_dataset.hdf5\", \"w\") as f:\n",
    "    f.create_dataset(\"X\", data=whitened_injected.cpu())\n",
    "    f.create_dataset(\"y\", data=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2405da79",
   "metadata": {},
   "source": [
    "# Example training setup for Basic search model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5309920a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml4gw.nn.resnet import ResNet1D\n",
    "\n",
    "architecture = ResNet1D(\n",
    "    in_channels=2,  # H1 and L1 as input channels\n",
    "    layers=[2, 2],  # Keep things small and do a ResNet10\n",
    "    classes=1,  # Single scalar-valued output\n",
    "    kernel_size=3,  # Size of convolutional kernels, not to be confused with data size\n",
    ").to(device)\n",
    "\n",
    "# And we can, e.g., pass the first element of our validation set\n",
    "with torch.no_grad():\n",
    "    print(architecture(whitened_injected[0][None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92baea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml4gw import augmentations, distributions, gw, transforms, waveforms\n",
    "from ml4gw.dataloading import ChunkedTimeSeriesDataset, Hdf5TimeSeriesDataset\n",
    "from ml4gw.utils.slicing import sample_kernels\n",
    "import torch\n",
    "from lightning import pytorch as pl\n",
    "import torchmetrics\n",
    "from torchmetrics.classification import BinaryAUROC\n",
    "\n",
    "from typing import Callable, Dict, List\n",
    "\n",
    "\n",
    "class Ml4gwDetectionModel(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    Model with methods for generating waveforms and\n",
    "    performing our preprocessing augmentations in\n",
    "    real-time on the GPU. Also loads training background\n",
    "    in chunks from disk, then samples batches from chunks.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        architecture: torch.nn.Module,\n",
    "        metric: torchmetrics.Metric,\n",
    "        ifos: List[str] = [\"H1\", \"L1\"],\n",
    "        kernel_length: float = 1.5,\n",
    "        # PSD/whitening args\n",
    "        fduration: float = 2,\n",
    "        psd_length: float = 16,\n",
    "        sample_rate: float = 2048,\n",
    "        fftlength: float = 2,\n",
    "        highpass: float = 32,\n",
    "        # Dataloading args\n",
    "        chunk_length: float = 128,  # we'll talk about chunks in a second\n",
    "        reads_per_chunk: int = 40,\n",
    "        learning_rate: float = 0.005,\n",
    "        batch_size: int = 256,\n",
    "        # Waveform generation args\n",
    "        waveform_prob: float = 0.5,\n",
    "        approximant: Callable = waveforms.cbc.IMRPhenomD,\n",
    "        param_dict: Dict[str, torch.distributions.Distribution] = param_dict,\n",
    "        waveform_duration: float = 8,\n",
    "        f_min: float = 20,\n",
    "        f_max: float = None,\n",
    "        f_ref: float = 20,\n",
    "        # Augmentation args\n",
    "        inversion_prob: float = 0.5,\n",
    "        reversal_prob: float = 0.5,\n",
    "        min_snr: float = 12,\n",
    "        max_snr: float = 100,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(\n",
    "            ignore=[\"architecture\", \"metric\", \"approximant\"]\n",
    "        )\n",
    "        self.nn = architecture\n",
    "        self.metric = metric\n",
    "\n",
    "        self.inverter = augmentations.SignalInverter(prob=inversion_prob)\n",
    "        self.reverser = augmentations.SignalReverser(prob=reversal_prob)\n",
    "\n",
    "        # real-time transformations defined with torch Modules\n",
    "        self.spectral_density = transforms.SpectralDensity(\n",
    "            sample_rate, fftlength, average=\"median\", fast=False\n",
    "        )\n",
    "        self.whitener = transforms.Whiten(\n",
    "            fduration, sample_rate, highpass=highpass\n",
    "        )\n",
    "\n",
    "        # get some geometry information about\n",
    "        # the interferometers we're going to project to\n",
    "        detector_tensors, vertices = gw.get_ifo_geometry(*ifos)\n",
    "        self.register_buffer(\"detector_tensors\", detector_tensors)\n",
    "        self.register_buffer(\"detector_vertices\", vertices)\n",
    "\n",
    "        # define some sky parameter distributions\n",
    "        self.param_dict = param_dict\n",
    "        self.dec = distributions.Cosine()\n",
    "        self.psi = torch.distributions.Uniform(0, torch.pi)\n",
    "        self.phi = torch.distributions.Uniform(\n",
    "            -torch.pi, torch.pi\n",
    "        )  # relative RAs of detector and source\n",
    "        self.waveform_generator = TimeDomainCBCWaveformGenerator(\n",
    "            approximant=approximant(),\n",
    "            sample_rate=sample_rate,\n",
    "            duration=waveform_duration,\n",
    "            f_min=f_min,\n",
    "            f_ref=f_ref,\n",
    "            right_pad=0.5,\n",
    "        ).to(self.device)\n",
    "\n",
    "        # rather than sample distances, we'll sample target SNRs.\n",
    "        # This way we can ensure we train our network on\n",
    "        # signals that are more detectable. We'll use a distribution\n",
    "        # that looks roughly like the natural sampled SNR distribution\n",
    "        self.snr = distributions.PowerLaw(min_snr, max_snr, -3)\n",
    "\n",
    "        # up front let's define some properties in units of samples\n",
    "        # Note the different usage of window_size from earlier\n",
    "        self.kernel_size = int(kernel_length * sample_rate)\n",
    "        self.window_size = self.kernel_size + int(fduration * sample_rate)\n",
    "        self.psd_size = int(psd_length * sample_rate)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.nn(X)\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        X, y = batch\n",
    "        y_hat = self(X)\n",
    "        loss = torch.nn.functional.binary_cross_entropy_with_logits(y_hat, y)\n",
    "        self.log(\"train_loss\", loss, on_step=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        X, y = batch\n",
    "        y_hat = self(X)\n",
    "        self.metric.update(y_hat, y)\n",
    "        self.log(\"valid_auroc\", self.metric, on_epoch=True, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        parameters = self.nn.parameters()\n",
    "        optimizer = torch.optim.AdamW(parameters, self.hparams.learning_rate)\n",
    "        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            optimizer,\n",
    "            self.hparams.learning_rate,\n",
    "            pct_start=0.1,\n",
    "            total_steps=self.trainer.estimated_stepping_batches,\n",
    "        )\n",
    "        scheduler_config = dict(scheduler=scheduler, interval=\"step\")\n",
    "        return dict(optimizer=optimizer, lr_scheduler=scheduler_config)\n",
    "\n",
    "    def configure_callbacks(self):\n",
    "        chkpt = pl.callbacks.ModelCheckpoint(monitor=\"valid_auroc\", mode=\"max\")\n",
    "        return [chkpt]\n",
    "\n",
    "    def generate_waveforms(self, batch_size: int) -> tuple[torch.Tensor, ...]:\n",
    "        rvs = torch.rand(size=(batch_size,))\n",
    "        mask = rvs < self.hparams.waveform_prob\n",
    "        num_injections = mask.sum().item()\n",
    "\n",
    "        params = {\n",
    "            k: v.sample((num_injections,)).to(device)\n",
    "            for k, v in self.param_dict.items()\n",
    "        }\n",
    "\n",
    "        params[\"s1z\"], params[\"s2z\"] = (\n",
    "            params[\"chi1\"], params[\"chi2\"]\n",
    "        )\n",
    "        params[\"mass_1\"], params[\"mass_2\"] = waveforms.conversion.chirp_mass_and_mass_ratio_to_components(\n",
    "            params[\"chirp_mass\"], params[\"mass_ratio\"]\n",
    "        )\n",
    "\n",
    "        hc, hp = self.waveform_generator(**params)\n",
    "        return hc, hp, mask\n",
    "\n",
    "    def project_waveforms(\n",
    "        self, hc: torch.Tensor, hp: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        # sample sky parameters\n",
    "        N = len(hc)\n",
    "        dec = self.dec.sample((N,)).to(hc)\n",
    "        psi = self.psi.sample((N,)).to(hc)\n",
    "        phi = self.phi.sample((N,)).to(hc)\n",
    "\n",
    "        # project to interferometer response\n",
    "        return gw.compute_observed_strain(\n",
    "            dec=dec,\n",
    "            psi=psi,\n",
    "            phi=phi,\n",
    "            detector_tensors=self.detector_tensors,\n",
    "            detector_vertices=self.detector_vertices,\n",
    "            sample_rate=self.hparams.sample_rate,\n",
    "            cross=hc,\n",
    "            plus=hp,\n",
    "        )\n",
    "\n",
    "    def rescale_snrs(\n",
    "        self, responses: torch.Tensor, psd: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        # make sure everything has the same number of frequency bins\n",
    "        num_freqs = int(responses.size(-1) // 2) + 1\n",
    "        if psd.size(-1) != num_freqs:\n",
    "            psd = torch.nn.functional.interpolate(\n",
    "                psd, size=(num_freqs,), mode=\"linear\"\n",
    "            )\n",
    "        N = len(responses)\n",
    "        target_snrs = self.snr.sample((N,)).to(responses.device)\n",
    "        return gw.reweight_snrs(\n",
    "            responses=responses.double(),\n",
    "            target_snrs=target_snrs,\n",
    "            psd=psd,\n",
    "            sample_rate=self.hparams.sample_rate,\n",
    "            highpass=self.hparams.highpass,\n",
    "        )\n",
    "\n",
    "    def sample_waveforms(self, responses: torch.Tensor) -> torch.Tensor:\n",
    "        # slice off random views of each waveform to inject in arbitrary positions\n",
    "        responses = responses[:, :, -self.window_size :]\n",
    "\n",
    "        # pad so that at least half the kernel always contains signals\n",
    "        pad = [0, int(self.window_size // 2)]\n",
    "        responses = torch.nn.functional.pad(responses, pad)\n",
    "        return sample_kernels(responses, self.window_size, coincident=True)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def augment(self, X: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        # break off \"background\" from target kernel and compute its PSD\n",
    "        # (in double precision since our scale is so small)\n",
    "        background, X = torch.split(\n",
    "            X, [self.psd_size, self.window_size], dim=-1\n",
    "        )\n",
    "        psd = self.spectral_density(background.double())\n",
    "\n",
    "        # Generate at most batch_size signals from our parameter distributions\n",
    "        # Keep a mask that indicates which rows to inject in\n",
    "        batch_size = X.size(0)\n",
    "        hc, hp, mask = self.generate_waveforms(batch_size)\n",
    "        hc, hp, mask = hc, hp, mask\n",
    "\n",
    "        # Augment with inversion and reversal\n",
    "        X = self.inverter(X)\n",
    "        X = self.reverser(X)\n",
    "\n",
    "        # sample sky parameters and project to responses, then\n",
    "        # rescale the response according to a randomly sampled SNR\n",
    "        responses = self.project_waveforms(hc, hp)\n",
    "        responses = self.rescale_snrs(responses, psd[mask])\n",
    "\n",
    "        # randomly slice out a window of the waveform, add it\n",
    "        # to our background, then whiten everything\n",
    "        responses = self.sample_waveforms(responses)\n",
    "        X[mask] += responses.float()\n",
    "        X = self.whitener(X, psd)\n",
    "\n",
    "        # create labels, marking 1s where we injected\n",
    "        y = torch.zeros((batch_size, 1), device=X.device)\n",
    "        y[mask] = 1\n",
    "        return X, y\n",
    "\n",
    "    def on_after_batch_transfer(self, batch, _):\n",
    "        # this is a parent method that lightning calls\n",
    "        # between when the batch gets moved to GPU and\n",
    "        # when it gets passed to the training_step.\n",
    "        # Apply our augmentations here\n",
    "        if self.trainer.training:\n",
    "            batch = self.augment(batch)\n",
    "        return batch\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        # Because our entire training dataset is generated\n",
    "        # on the fly, the traditional idea of an \"epoch\"\n",
    "        # meaning one pass through the training set doesn't\n",
    "        # apply here. Instead, we have to set the number\n",
    "        # of batches per epoch ourselves, which really\n",
    "        # just amounts to deciding how often we want\n",
    "        # to run over the validation dataset.\n",
    "        samples_per_epoch = 3000\n",
    "        batches_per_epoch = (\n",
    "            int((samples_per_epoch - 1) // self.hparams.batch_size) + 1\n",
    "        )\n",
    "        batches_per_chunk = int(batches_per_epoch // 10)\n",
    "        chunks_per_epoch = int(batches_per_epoch // batches_per_chunk) + 1\n",
    "\n",
    "        # Hdf5TimeSeries dataset samples batches from disk.\n",
    "        # In this instance, we'll make our batches really large so that\n",
    "        # we can treat them as chunks to sample training batches from\n",
    "        fnames = list(background_dir.iterdir())\n",
    "        dataset = Hdf5TimeSeriesDataset(\n",
    "            fnames=fnames,\n",
    "            channels=self.hparams.ifos,\n",
    "            kernel_size=int(\n",
    "                self.hparams.chunk_length * self.hparams.sample_rate\n",
    "            ),\n",
    "            batch_size=self.hparams.reads_per_chunk,\n",
    "            batches_per_epoch=chunks_per_epoch,\n",
    "            coincident=False,\n",
    "        )\n",
    "\n",
    "        # sample batches to pass to our NN from the chunks loaded from disk\n",
    "        return ChunkedTimeSeriesDataset(\n",
    "            dataset,\n",
    "            kernel_size=self.window_size + self.psd_size,\n",
    "            batch_size=self.hparams.batch_size,\n",
    "            batches_per_chunk=batches_per_chunk,\n",
    "            coincident=False,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        with h5py.File(data_dir / \"validation_dataset.hdf5\", \"r\") as f:\n",
    "            X = torch.Tensor(f[\"X\"][:])\n",
    "            y = torch.Tensor(f[\"y\"][:])\n",
    "        dataset = torch.utils.data.TensorDataset(X, y)\n",
    "        return torch.utils.data.DataLoader(\n",
    "            dataset,\n",
    "            batch_size=self.hparams.batch_size * 4,\n",
    "            shuffle=False,\n",
    "            pin_memory=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066bfec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture = ResNet1D(\n",
    "    in_channels=2,\n",
    "    layers=[2, 2],\n",
    "    classes=1,\n",
    "    kernel_size=3,\n",
    ").to(device)\n",
    "\n",
    "max_fpr = 1e-3\n",
    "metric = BinaryAUROC(max_fpr=max_fpr)\n",
    "\n",
    "model = Ml4gwDetectionModel(\n",
    "    architecture=architecture,\n",
    "    metric=metric,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b441045b",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = data_dir / \"logs\"\n",
    "\n",
    "logger = pl.loggers.CSVLogger(log_dir, name=\"ml4gw-expt\")\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=20,\n",
    "    precision=\"16-mixed\",\n",
    "    log_every_n_steps=5,\n",
    "    logger=logger,\n",
    "    callbacks=[pl.callbacks.RichProgressBar()],\n",
    "    accelerator=\"auto\",\n",
    ")\n",
    "trainer.fit(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lecture_3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
